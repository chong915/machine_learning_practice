{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "In this project, you will implement Na誰ve Bayes to predict if a name is male or female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# add p03 folder\n",
    "sys.path.insert(0, './p03/')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashfeatures(baby, B, FIX):\n",
    "    v = np.zeros(B)\n",
    "    for m in range(FIX):\n",
    "        featurestring = \"prefix\" + baby[:m]\n",
    "        v[hash(featurestring) % B] = 1\n",
    "        featurestring = \"suffix\" + baby[-1*m:]\n",
    "        v[hash(featurestring) % B] = 1\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name2features(filename, B=128, FIX=3, LoadFile=True):\n",
    "    \"\"\"\n",
    "    Output:\n",
    "    X : n feature vectors of dimension B, (nxB)\n",
    "    \"\"\"\n",
    "    # read in baby names\n",
    "    if LoadFile:\n",
    "        with open(filename, 'r') as f:\n",
    "            babynames = [x.rstrip() for x in f.readlines() if len(x) > 0]\n",
    "    else:\n",
    "        babynames = filename.split('\\n')\n",
    "    n = len(babynames)\n",
    "    X = np.zeros((n, B))\n",
    "    for i in range(n):\n",
    "        X[i,:] = hashfeatures(babynames[i], B, FIX)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It reads every name in the given file and converts it into a 128-dimensional feature vector. </p>\n",
    "\n",
    "Can you figure out what the features are? (Understanding how these features are constructed will help you later on in the competition.)\n",
    "\n",
    "We have provided you with a python function genTrainFeatures, which calls this script, transforms the names into features and loads them into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genTrainFeatures(dimension=128, fix=3):\n",
    "    \"\"\"\n",
    "    function [x,y]=genTrainFeatures\n",
    "    \n",
    "    This function calls the python script \"name2features.py\" \n",
    "    to convert names into feature vectors and loads in the training data. \n",
    "    \n",
    "    \n",
    "    Output: \n",
    "    x: n feature vectors of dimensionality d [d,n]\n",
    "    y: n labels (-1 = girl, +1 = boy)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load in the data\n",
    "    Xgirls = name2features(\"girls.train\", B=dimension, FIX=fix)\n",
    "    Xboys = name2features(\"boys.train\", B=dimension, FIX=fix)\n",
    "    X = np.concatenate([Xgirls, Xboys])\n",
    "    \n",
    "    # Generate Labels\n",
    "    Y = np.concatenate([-np.ones(len(Xgirls)), np.ones(len(Xboys))])\n",
    "    \n",
    "    # shuffle data into random order\n",
    "    ii = np.random.permutation([i for i in range(len(Y))])\n",
    "    \n",
    "    return X[ii, :], Y[ii]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call the following command to load in the features and the labels of all boys and girls names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = genTrainFeatures(128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Na誰ve Bayes Classifier\n",
    "\n",
    "The Na誰ve Bayes classifier is a linear classifier based on Bayes Rule. The following questions will ask you to finish these functions in a pre-defined order. <br>\n",
    "As a general rule, you should avoid tight loops at all cost.\n",
    "\n",
    "(a) Estimate the class probability P(Y) in  naivebayesPY . This should return the probability that a sample in the training set is positive or negative, independent of its features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivebayesPY(x,y):\n",
    "    \"\"\"\n",
    "    function [pos,neg] = naivebayesPY(x,y);\n",
    "\n",
    "    Computation of P(Y)\n",
    "    Input:\n",
    "        x : n input vectors of d dimensions (nxd)\n",
    "        y : n labels (-1 or +1) (nx1)\n",
    "\n",
    "    Output:\n",
    "        pos: probability p(y=1)\n",
    "        neg: probability p(y=-1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # add one positive and negative example to avoid division by zero (\"plus-one smoothing\")\n",
    "    y = np.concatenate([y, [-1,1]])\n",
    "    n = len(y)\n",
    "    pos = len(y[y == 1])/n\n",
    "    return pos, 1-pos\n",
    "\n",
    "#</GRADED>\n",
    "\n",
    "pos,neg = naivebayesPY(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Estimate the conditional probabilities P(X|Y) in  naivebayesPXY . Use a multinomial distribution as model. This will return the probability vectors for all features given a class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivebayesPXY(x,y):\n",
    "    \"\"\"\n",
    "    function [posprob,negprob] = naivebayesPXY(x,y);\n",
    "    \n",
    "    Computation of P(X|Y)\n",
    "    Input:\n",
    "        x : n input vectors of d dimensions (nxd)\n",
    "        y : n labels (-1 or +1) (nx1)\n",
    "    \n",
    "    Output:\n",
    "        PXY_pos: probability vector of p(x|y=1) (1xd)\n",
    "        PXY_neg: probability vector of p(x|y=-1) (1xd)\n",
    "    \"\"\"\n",
    "    \n",
    "    # add one positive and negative example to avoid division by zero (\"plus-one smoothing\")\n",
    "    n, d = x.shape\n",
    "    x = np.concatenate([x, np.ones((2,d))])   #add two observations (rows) of just 1s\n",
    "    y = np.concatenate([y, [-1,1]])           #add two labels for the two rows\n",
    "    n, d = x.shape\n",
    "    \n",
    "    # grab rows that have positive (stored as pos) and negative (neg)\n",
    "    pos = x[y==1]\n",
    "    neg = x[y==-1]\n",
    "    \n",
    "    # get the total word count (non-distinct) in the positive words, and in the negative words. each is a scalar\n",
    "    pos_letters = np.sum(pos)\n",
    "    neg_letters = np.sum(neg)\n",
    "    \n",
    "    # sum accross observations to count how many times each word appears in the observations, given that the word is positive (or negative)\n",
    "    pos_letter_counts = np.sum(pos, axis=0)\n",
    "    neg_letter_counts = np.sum(neg, axis=0)\n",
    "    \n",
    "    #make probabilities given letter counts (pos_letter_counts and neg_letter_counts), and total number of letters (pos_letters and neg_letters)\n",
    "    PXY_pos = pos_letter_counts/pos_letters\n",
    "    PXY_neg = neg_letter_counts/neg_letters\n",
    "    \n",
    "    return PXY_pos, PXY_neg\n",
    "\n",
    "PXY_pos, PXY_neg = naivebayesPXY(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9455943956563633"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def naivebayes(x,y,xtest):\n",
    "    \"\"\"\n",
    "    function logratio = naivebayes(x,y);\n",
    "    \n",
    "    Computation of log P(Y|X=x1) using Bayes Rule\n",
    "    Input:\n",
    "        x : n input vectors of d dimensions (nxd)\n",
    "        y : n labels (-1 or +1)\n",
    "        xtest: input vector of d dimensions (1xd)\n",
    "    \n",
    "    Output:\n",
    "        logratio: log (P(Y=1|X=xtest)*P(Y=1)/P(Y=-1|X=xtest)*P(Y=-1))\n",
    "    \"\"\"\n",
    "    PXY_pos, PXY_neg = naivebayesPXY(x,y)\n",
    "    PY_pos, PY_neg = naivebayesPY(x,y)\n",
    "    \n",
    "    print(PXY_pos.shape)\n",
    "    # evaluate xtest, and calculate P(Y = 1|X=xtest) and P(Y=-1|X=xtest)\n",
    "    \n",
    "    #find indicies for letters in incoming text\n",
    "    xtest_idx = np.where(xtest == 1)\n",
    "    \n",
    "    # Calculate P(Y=1|X=xtest)*P(Y=1) and P(Y=-1|X=xtest)*P(Y=-1)\n",
    "    PXY_pos_PY_pos = np.prod(PXY_pos[xtest_idx])*PY_pos\n",
    "    PXY_neg_PY_neg = np.prod(PXY_neg[xtest_idx])*PY_neg\n",
    "    \n",
    "    # return likelihood ratio\n",
    "    return np.log(PXY_pos_PY_pos/PXY_neg_PY_neg)\n",
    "\n",
    "p = naivebayes(X,Y,X[0,:])\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Na誰ve Bayes can also be written as a linear classifier. Implement this in  naivebayesCL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naivebayesCL(x,y):\n",
    "    \"\"\"\n",
    "    function [w,b]=naivebayesCL(x,y);\n",
    "    Implementation of a Naive Bayes classifier\n",
    "    Input:\n",
    "        x : n input vectors of d dimensions (nxd)\n",
    "        y : n labels (-1 or +1)\n",
    "\n",
    "    Output:\n",
    "        w : weight vector of d dimensions\n",
    "        b : bias (scalar)\n",
    "    \"\"\"\n",
    "    \n",
    "    n, d = x.shape\n",
    "    \n",
    "    PXY_pos, PXY_neg = naivebayesPXY(x,y)\n",
    "    PY_pos, PY_neg = naivebayesPY(x,y)\n",
    "    \n",
    "    # w = log( P(X_j|Y=1) / P(X_j|Y=0) )\n",
    "    w = np.array([np.log(PXY_pos_j/PXY_neg_j) for PXY_pos_j, PXY_neg_j in zip(PXY_pos, PXY_neg)])\n",
    "    b = np.log(PY_pos/PY_neg)\n",
    "    return w, b \n",
    "\n",
    "w,b = naivebayesCL(X,Y)\n",
    "#w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Implement  classifyLinear that applies a linear weight vector and bias to a set of input vectors and outputs their predictions. (You can use your answer from the previous project.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error: 21.58%\n"
     ]
    }
   ],
   "source": [
    "#<GRADED>\n",
    "def classifyLinear(x,w,b=0,hyper=0):\n",
    "    \"\"\"\n",
    "    function preds=classifyLinear(x,w,b);\n",
    "    \n",
    "    Make predictions with a linear classifier\n",
    "    Input:\n",
    "        x : n input vectors of d dimensions (nxd)\n",
    "        w : weight vector of d dimensions\n",
    "        b : bias (optional)\n",
    "    \n",
    "    Output:\n",
    "        preds: predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    result = x.dot(w) + b\n",
    "    # is there a way to do this with numpy arrays?\n",
    "    pred = [1*(num>hyper) + -1*(num<=hyper) for num in result]\n",
    "    \n",
    "    return np.array(pred)\n",
    "\n",
    "print('Training error: %.2f%%' % (100 *(classifyLinear(X, w, b) != Y).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now test your code with the following interactive name classification script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Training classifier ...\n",
      "Training error: 21.58%\n",
      "Please enter your name>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Joe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe, I am sure you are a nice boy.\n",
      "\n",
      "Please enter your name>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Donald\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald, I am sure you are a nice boy.\n",
      "\n",
      "Please enter your name>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " Allen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allen, I am sure you are a nice boy.\n",
      "\n",
      "Please enter your name>\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "DIMS = 128\n",
    "print('Loading data ...')\n",
    "X,Y = genTrainFeatures(DIMS)\n",
    "print('Training classifier ...')\n",
    "w,b=naivebayesCL(X,Y)\n",
    "error = np.mean(classifyLinear(X,w,b) != Y)\n",
    "print('Training error: %.2f%%' % (100 * error))\n",
    "\n",
    "while True:\n",
    "    print('Please enter your name>')\n",
    "    yourname = input()\n",
    "    if len(yourname) < 1:\n",
    "        break\n",
    "    xtest = name2features(yourname,B=DIMS,LoadFile=False)\n",
    "    pred = classifyLinear(xtest,w,b)[0]\n",
    "    if pred > 0:\n",
    "        print(\"%s, I am sure you are a nice boy.\\n\" % yourname)\n",
    "    else:\n",
    "        print(\"%s, I am sure you are a nice girl.\\n\" % yourname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
